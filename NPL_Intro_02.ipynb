{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selfor21/NLP---Natural-Language-Processing/blob/main/NPL_Intro_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP - Natural Language Processing\n",
        "\n",
        "## Week 02\n",
        "## *Corpus* - Textual Similarity\n"
      ],
      "metadata": {
        "id": "MD5gnbZ1QEWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Corpus* Review"
      ],
      "metadata": {
        "id": "Hdkb0UKxC_I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poema = \"\"\"E agora, José?\n",
        "A festa acabou,\n",
        "a luz apagou,\n",
        "o povo sumiu,\n",
        "a noite esfriou,\n",
        "e agora, José?\n",
        "e agora, você?\n",
        "você que é sem nome,\n",
        "que zomba dos outros,\n",
        "você que faz versos,\n",
        "que ama, protesta?\n",
        "e agora, José?\n",
        "\n",
        "Está sem mulher,\n",
        "está sem discurso,\n",
        "está sem carinho,\n",
        "já não pode beber,\n",
        "já não pode fumar,\n",
        "cuspir já não pode,\n",
        "a noite esfriou,\n",
        "o dia não veio,\n",
        "o bonde não veio,\n",
        "o riso não veio,\n",
        "não veio a utopia\n",
        "e tudo acabou\n",
        "e tudo fugiu\n",
        "e tudo mofou,\n",
        "e agora, José?\n",
        "\n",
        "E agora, José?\n",
        "Sua doce palavra,\n",
        "seu instante de febre,\n",
        "sua gula e jejum,\n",
        "sua biblioteca,\n",
        "sua lavra de ouro,\n",
        "seu terno de vidro,\n",
        "sua incoerência,\n",
        "seu ódio - e agora?\n",
        "\n",
        "Com a chave na mão\n",
        "quer abrir a porta,\n",
        "não existe porta;\n",
        "quer morrer no mar,\n",
        "mas o mar secou;\n",
        "quer ir para Minas,\n",
        "Minas não há mais.\n",
        "José, e agora?\n",
        "\n",
        "Se você gritasse,\n",
        "se você gemesse,\n",
        "se você tocasse\n",
        "a valsa vienense,\n",
        "se você dormisse,\n",
        "se você cansasse,\n",
        "se você morresse...\n",
        "Mas você não morre,\n",
        "você é duro, José!\n",
        "\n",
        "Sozinho no escuro\n",
        "qual bicho-do-mato,\n",
        "sem teogonia,\n",
        "sem parede nua\n",
        "para se encostar,\n",
        "sem cavalo preto\n",
        "que fuja a galope,\n",
        "você marcha, José!\n",
        "José, para onde?\"\"\"\n"
      ],
      "metadata": {
        "id": "wYkXdvkURMde"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import tokenize\n",
        "nltk.download('punkt') # tokenizEr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jApV77_rUBgF",
        "outputId": "a73d8e58-2edb-4958-cb69-a975ba6a749b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Counting *tokens* and *types*"
      ],
      "metadata": {
        "id": "1LwpkxXORdtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenize.word_tokenize(poema, language=\"portuguese\")\n",
        "minusculas = tokenize.word_tokenize(poema.lower(), language=\"portuguese\")\n",
        "\n",
        "vocabulario = set(minusculas)\n",
        "\n",
        "print(\"Quantity of tokens: \",len(tokens))\n",
        "print(\"Quantity of types: \",len(vocabulario))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbDbLBsORePM",
        "outputId": "7b8f45e0-8780-4557-c63e-1dd06b2d3c2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantity of tokens:  274\n",
            "Quantity of types:  109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)\n",
        "print(len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvtUCWdZRpR_",
        "outputId": "fdbf1263-4e47-46fb-dd19-f6bf273088b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['E', 'agora', ',', 'José', '?', 'A', 'festa', 'acabou', ',', 'a', 'luz', 'apagou', ',', 'o', 'povo', 'sumiu', ',', 'a', 'noite', 'esfriou', ',', 'e', 'agora', ',', 'José', '?', 'e', 'agora', ',', 'você', '?', 'você', 'que', 'é', 'sem', 'nome', ',', 'que', 'zomba', 'dos', 'outros', ',', 'você', 'que', 'faz', 'versos', ',', 'que', 'ama', ',', 'protesta', '?', 'e', 'agora', ',', 'José', '?', 'Está', 'sem', 'mulher', ',', 'está', 'sem', 'discurso', ',', 'está', 'sem', 'carinho', ',', 'já', 'não', 'pode', 'beber', ',', 'já', 'não', 'pode', 'fumar', ',', 'cuspir', 'já', 'não', 'pode', ',', 'a', 'noite', 'esfriou', ',', 'o', 'dia', 'não', 'veio', ',', 'o', 'bonde', 'não', 'veio', ',', 'o', 'riso', 'não', 'veio', ',', 'não', 'veio', 'a', 'utopia', 'e', 'tudo', 'acabou', 'e', 'tudo', 'fugiu', 'e', 'tudo', 'mofou', ',', 'e', 'agora', ',', 'José', '?', 'E', 'agora', ',', 'José', '?', 'Sua', 'doce', 'palavra', ',', 'seu', 'instante', 'de', 'febre', ',', 'sua', 'gula', 'e', 'jejum', ',', 'sua', 'biblioteca', ',', 'sua', 'lavra', 'de', 'ouro', ',', 'seu', 'terno', 'de', 'vidro', ',', 'sua', 'incoerência', ',', 'seu', 'ódio', '-', 'e', 'agora', '?', 'Com', 'a', 'chave', 'na', 'mão', 'quer', 'abrir', 'a', 'porta', ',', 'não', 'existe', 'porta', ';', 'quer', 'morrer', 'no', 'mar', ',', 'mas', 'o', 'mar', 'secou', ';', 'quer', 'ir', 'para', 'Minas', ',', 'Minas', 'não', 'há', 'mais', '.', 'José', ',', 'e', 'agora', '?', 'Se', 'você', 'gritasse', ',', 'se', 'você', 'gemesse', ',', 'se', 'você', 'tocasse', 'a', 'valsa', 'vienense', ',', 'se', 'você', 'dormisse', ',', 'se', 'você', 'cansasse', ',', 'se', 'você', 'morresse', '...', 'Mas', 'você', 'não', 'morre', ',', 'você', 'é', 'duro', ',', 'José', '!', 'Sozinho', 'no', 'escuro', 'qual', 'bicho-do-mato', ',', 'sem', 'teogonia', ',', 'sem', 'parede', 'nua', 'para', 'se', 'encostar', ',', 'sem', 'cavalo', 'preto', 'que', 'fuja', 'a', 'galope', ',', 'você', 'marcha', ',', 'José', '!', 'José', ',', 'para', 'onde', '?']\n",
            "274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocabulario)\n",
        "print(len(vocabulario))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-sIqnL-Rs9X",
        "outputId": "bf64cf6a-b233-4375-83bd-a10c9a6cf435"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'terno', 'parede', 'não', 'fumar', ';', 'tudo', '-', 'utopia', 'está', 'valsa', 'veio', 'outros', 'fugiu', 'quer', 'morrer', 'josé', 'beber', 'incoerência', 'cansasse', 'ouro', 'chave', 'febre', 'escuro', 'vienense', 'vidro', 'sua', 'mofou', 'pode', 'faz', 'galope', 'acabou', 'já', 'marcha', '!', 'nome', 'fuja', 'cuspir', 'cavalo', 'secou', 'abrir', 'encostar', 'biblioteca', 'instante', 'dia', 'no', 'duro', 'existe', 'palavra', 'zomba', 'teogonia', 'é', 'porta', 'sumiu', 'de', ',', 'agora', 'ama', 'mas', 'que', 'você', 'a', 'seu', 'discurso', 'povo', 'festa', 'jejum', 'mais', 'doce', 'o', 'e', 'lavra', 'nua', 'preto', 'se', 'dormisse', 'mão', 'qual', 'morre', '...', 'minas', 'riso', 'noite', 'gemesse', 'versos', 'tocasse', 'protesta', 'mulher', '.', 'gritasse', 'bicho-do-mato', '?', 'ódio', 'onde', 'dos', 'esfriou', 'gula', 'morresse', 'sozinho', 'mar', 'sem', 'ir', 'carinho', 'há', 'para', 'luz', 'bonde', 'com', 'na', 'apagou'}\n",
            "109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentences Segmentation"
      ],
      "metadata": {
        "id": "AhhIvRTRR1oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentencas = nltk.sent_tokenize(poema, language=\"portuguese\")\n",
        "print(sentencas)\n",
        "print(len(sentencas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g00STaIFR1L7",
        "outputId": "1b8f39b9-ed9b-4a12-e0a5-04147e2261bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['E agora, José?', 'A festa acabou,\\na luz apagou,\\no povo sumiu,\\na noite esfriou,\\ne agora, José?', 'e agora, você?', 'você que é sem nome,\\nque zomba dos outros,\\nvocê que faz versos,\\nque ama, protesta?', 'e agora, José?', 'Está sem mulher,\\nestá sem discurso,\\nestá sem carinho,\\njá não pode beber,\\njá não pode fumar,\\ncuspir já não pode,\\na noite esfriou,\\no dia não veio,\\no bonde não veio,\\no riso não veio,\\nnão veio a utopia\\ne tudo acabou\\ne tudo fugiu\\ne tudo mofou,\\ne agora, José?', 'E agora, José?', 'Sua doce palavra,\\nseu instante de febre,\\nsua gula e jejum,\\nsua biblioteca,\\nsua lavra de ouro,\\nseu terno de vidro,\\nsua incoerência,\\nseu ódio - e agora?', 'Com a chave na mão\\nquer abrir a porta,\\nnão existe porta;\\nquer morrer no mar,\\nmas o mar secou;\\nquer ir para Minas,\\nMinas não há mais.', 'José, e agora?', 'Se você gritasse,\\nse você gemesse,\\nse você tocasse\\na valsa vienense,\\nse você dormisse,\\nse você cansasse,\\nse você morresse...', 'Mas você não morre,\\nvocê é duro, José!', 'Sozinho no escuro\\nqual bicho-do-mato,\\nsem teogonia,\\nsem parede nua\\npara se encostar,\\nsem cavalo preto\\nque fuja a galope,\\nvocê marcha, José!', 'José, para onde?']\n",
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Textual Similarity"
      ],
      "metadata": {
        "id": "McyOtSv6DQU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UzzAr9N372mX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = ['Goku is a hero in the Dragon Ball since 1989! Goku saved the earth so many times.',\n",
        "         'The 7 Dragon balls can make wishes come true! Each ball contains his own dragon.',\n",
        "         'If the wishes are superfluous, the dragon balls will become dark.' ,\n",
        "         'Seiya is a bronze knight and is one of the main Knights of the Zodiac. He saved Athena several times.',\n",
        "         \"A knight of the zodiac wear a bronze, silver or a gold cloth to protect Athena.\",\n",
        "         'Saint Seiya: Knights of the Zodiac is a Japanese manga in which mystical warriors called the Saints fight wearing sacred cloths.']\n",
        "classes = ['Dragon Ball', 'Dragon Ball', 'Dragon Ball', 'Cav. Zod.', 'Cav. Zod.', 'Cav. Zod.']\n",
        "\n",
        "df = pd.DataFrame({'texts': texts, 'classes': classes})\n",
        "print(df)"
      ],
      "metadata": {
        "id": "lvBveXtE74TR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a85743-4116-4385-8691-7622d9fc3d2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts      classes\n",
            "0  Goku is a hero in the Dragon Ball since 1989! ...  Dragon Ball\n",
            "1  The 7 Dragon balls can make wishes come true! ...  Dragon Ball\n",
            "2  If the wishes are superfluous, the dragon ball...  Dragon Ball\n",
            "3  Seiya is a bronze knight and is one of the mai...    Cav. Zod.\n",
            "4  A knight of the zodiac wear a bronze, silver o...    Cav. Zod.\n",
            "5  Saint Seiya: Knights of the Zodiac is a Japane...    Cav. Zod.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Textual Similarity based in characters"
      ],
      "metadata": {
        "id": "KPzlLxzl6R00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Levenshtein Distance\n",
        "\n",
        "\"Created in 1965 by russian matematician Vladimir Levenshtein (1935-2017). Distance value describes minimun number of inserts, deletions and substitutions needed to transform one *string* in another.\"\n",
        "\n",
        "SOURCE: [Distância de Levenshtein e similaridade de texto em Python](http://stackabuse.com/levenshtein-distance-and-text-similarity-in-python/)"
      ],
      "metadata": {
        "id": "5uRcpUp96ZVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein(seq1, seq2):\n",
        "    # criar uma matriz\n",
        "    size_x = len(seq1) + 1\n",
        "    size_y = len(seq2) + 1\n",
        "    matrix = np.zeros ((size_x, size_y))\n",
        "\n",
        "    # setar número de colunas (0, n-1)\n",
        "    for x in range(size_x):\n",
        "        matrix [x, 0] = x\n",
        "\n",
        "    # setar número de linhas (0, n-1)\n",
        "    for y in range(size_y):\n",
        "        matrix [0, y] = y\n",
        "\n",
        "    # calcular a distancia\n",
        "    for x in range(1, size_x):\n",
        "        for y in range(1, size_y):\n",
        "            # se os caracteres sao iguais, nao aumenta a distancia\n",
        "            if seq1[x-1] == seq2[y-1]:\n",
        "                matrix [x,y] = matrix[x-1, y-1]\n",
        "            # se são diferentes, aumenta a distancia em 1\n",
        "            else:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1,y] + 1,\n",
        "                    matrix[x-1,y-1] + 1,\n",
        "                    matrix[x,y-1] + 1\n",
        "                )\n",
        "\n",
        "    # imprime a matriz de calculo da distancia\n",
        "    # list(seq1) converte string em uma lista de caracteres\n",
        "    print(pd.DataFrame(matrix[1:,1:], index=list(seq1), columns=list(seq2)))\n",
        "\n",
        "    return (matrix[size_x - 1, size_y - 1])"
      ],
      "metadata": {
        "id": "8L9lF8VC6i0U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "levenshtein('medicina','medico')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ2QkBxiHpiz",
        "outputId": "55425444-9dab-4290-b3e8-bb820e9d9011"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     m    e    d    i    c    o\n",
            "m  0.0  1.0  2.0  3.0  4.0  5.0\n",
            "e  1.0  0.0  1.0  2.0  3.0  4.0\n",
            "d  2.0  1.0  0.0  1.0  2.0  3.0\n",
            "i  3.0  2.0  1.0  0.0  1.0  2.0\n",
            "c  4.0  3.0  2.0  1.0  0.0  1.0\n",
            "i  5.0  4.0  3.0  2.0  1.0  1.0\n",
            "n  6.0  5.0  4.0  3.0  2.0  2.0\n",
            "a  7.0  6.0  5.0  4.0  3.0  3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando a distância de Levenshtein para comparar textos/sentenças\n",
        "print(df)\n",
        "print (\"------\")\n",
        "doc_id_a = 3 # id do texto 1\n",
        "doc_id_b = 2 # id do texto 2\n",
        "print(\"texto 1: \",df.loc[doc_id_a]['texts'])\n",
        "print(\"texto 2: \",df.loc[doc_id_b]['texts'])\n",
        "print (\"------\")\n",
        "\n",
        "levenshtein(df.loc[doc_id_a]['texts'],df.loc[doc_id_b]['texts'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRz_I16hHyqW",
        "outputId": "319812d3-e10c-44bc-cc7d-b91a9ec1dc5e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts      classes\n",
            "0  Goku is a hero in the Dragon Ball since 1989! ...  Dragon Ball\n",
            "1  The 7 Dragon balls can make wishes come true! ...  Dragon Ball\n",
            "2  If the wishes are superfluous, the dragon ball...  Dragon Ball\n",
            "3  Seiya is a bronze knight and is one of the mai...    Cav. Zod.\n",
            "4  A knight of the zodiac wear a bronze, silver o...    Cav. Zod.\n",
            "5  Saint Seiya: Knights of the Zodiac is a Japane...    Cav. Zod.\n",
            "------\n",
            "texto 1:  Seiya is a bronze knight and is one of the main Knights of the Zodiac. He saved Athena several times.\n",
            "texto 2:  If the wishes are superfluous, the dragon balls will become dark.\n",
            "------\n",
            "        I      f           t     h     e           w     i     s  ...     c  \\\n",
            "S     1.0    2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  ...  56.0   \n",
            "e     2.0    2.0   3.0   4.0   5.0   5.0   6.0   7.0   8.0   9.0  ...  55.0   \n",
            "i     3.0    3.0   3.0   4.0   5.0   6.0   6.0   7.0   7.0   8.0  ...  54.0   \n",
            "y     4.0    4.0   4.0   4.0   5.0   6.0   7.0   7.0   8.0   8.0  ...  54.0   \n",
            "a     5.0    5.0   5.0   5.0   5.0   6.0   7.0   8.0   8.0   9.0  ...  53.0   \n",
            "..    ...    ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
            "i    97.0   96.0  95.0  94.0  93.0  92.0  91.0  91.0  90.0  89.0  ...  74.0   \n",
            "m    98.0   97.0  96.0  95.0  94.0  93.0  92.0  92.0  91.0  90.0  ...  75.0   \n",
            "e    99.0   98.0  97.0  96.0  95.0  94.0  93.0  93.0  92.0  91.0  ...  76.0   \n",
            "s   100.0   99.0  98.0  97.0  96.0  95.0  94.0  94.0  93.0  92.0  ...  76.0   \n",
            ".   101.0  100.0  99.0  98.0  97.0  96.0  95.0  95.0  94.0  93.0  ...  77.0   \n",
            "\n",
            "       o     m     e           d     a     r     k     .  \n",
            "S   57.0  58.0  59.0  60.0  61.0  62.0  63.0  64.0  65.0  \n",
            "e   56.0  57.0  58.0  59.0  60.0  61.0  62.0  63.0  64.0  \n",
            "i   55.0  56.0  57.0  58.0  59.0  60.0  61.0  62.0  63.0  \n",
            "y   55.0  56.0  57.0  58.0  59.0  60.0  61.0  62.0  63.0  \n",
            "a   54.0  55.0  56.0  57.0  58.0  59.0  60.0  61.0  62.0  \n",
            "..   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
            "i   74.0  74.0  74.0  73.0  73.0  73.0  74.0  75.0  75.0  \n",
            "m   75.0  74.0  75.0  74.0  74.0  74.0  74.0  75.0  76.0  \n",
            "e   76.0  75.0  74.0  75.0  75.0  75.0  75.0  75.0  76.0  \n",
            "s   77.0  76.0  75.0  75.0  76.0  76.0  76.0  76.0  76.0  \n",
            ".   77.0  77.0  76.0  76.0  76.0  77.0  77.0  77.0  76.0  \n",
            "\n",
            "[101 rows x 65 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76.0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similaridade Textual baseada em Termos"
      ],
      "metadata": {
        "id": "dDyK54G5K8MP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vetorizando os documentos de treinamento"
      ],
      "metadata": {
        "id": "g9AZrOraTj2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\"\"\"CREATING vetorizer object  (lowercase, retrieving stopwords from a list\n",
        "   and terms with occurrences minimum two documents\"\"\"\n",
        "vetorizador = CountVectorizer(lowercase=True,\n",
        "                              stop_words=['is', 'are', 'a', 'or', 'to', 'in', 'the', 'so', 'since', 'many', 'of'],\n",
        "                              min_df=2,\n",
        "                              dtype=np.int16\n",
        "                              )"
      ],
      "metadata": {
        "id": "v-9zKxY6776n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo o vocabulário\n",
        "vetorizador.fit(df['texts'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "EnqcxLMT8DZ7",
        "outputId": "caf79c74-7c05-4480-8660-fcd5661e4043"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(dtype=<class 'numpy.int16'>, min_df=2,\n",
              "                stop_words=['is', 'are', 'a', 'or', 'to', 'in', 'the', 'so',\n",
              "                            'since', 'many', 'of'])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(dtype=&lt;class &#x27;numpy.int16&#x27;&gt;, min_df=2,\n",
              "                stop_words=[&#x27;is&#x27;, &#x27;are&#x27;, &#x27;a&#x27;, &#x27;or&#x27;, &#x27;to&#x27;, &#x27;in&#x27;, &#x27;the&#x27;, &#x27;so&#x27;,\n",
              "                            &#x27;since&#x27;, &#x27;many&#x27;, &#x27;of&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(dtype=&lt;class &#x27;numpy.int16&#x27;&gt;, min_df=2,\n",
              "                stop_words=[&#x27;is&#x27;, &#x27;are&#x27;, &#x27;a&#x27;, &#x27;or&#x27;, &#x27;to&#x27;, &#x27;in&#x27;, &#x27;the&#x27;, &#x27;so&#x27;,\n",
              "                            &#x27;since&#x27;, &#x27;many&#x27;, &#x27;of&#x27;])</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vetorizador.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y440Hv8bQf_c",
        "outputId": "18c4414c-c27c-4726-f609-c4bcbcda586e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['athena' 'ball' 'balls' 'bronze' 'dragon' 'knight' 'knights' 'saved'\n",
            " 'seiya' 'times' 'wishes' 'zodiac']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando a representação estruturada a partir do vocabulário ajustado\n",
        "representacao = vetorizador.transform(df['texts'])\n",
        "# A representação retornada é uma matriz em um formato esparso  (posso gerar o array usando toArray())\n",
        "representacao\n",
        "rep_array = representacao.toarray() # a partir daqui podemos aplicar as funções de similaridade\n",
        "print(rep_array)"
      ],
      "metadata": {
        "id": "Ry1DbRvz7IBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1c8eb1-2266-4076-c09d-50e3dd03a74a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 0 1 0 0 1 0 1 0 0]\n",
            " [0 1 1 0 2 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 1 0 0 0 0 0 1 0]\n",
            " [1 0 0 1 0 1 1 1 1 1 0 1]\n",
            " [1 0 0 1 0 1 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 1 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine"
      ],
      "metadata": {
        "id": "rspLQ4Pq_gwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "matrix_sim = (cosine_similarity(rep_array))\n",
        "rounded = np.round(matrix_sim, 3)"
      ],
      "metadata": {
        "id": "4cqsxo4w7J3r"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rounded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ6CXkxI7Lz8",
        "outputId": "ef52451c-ade0-458a-cbb6-a27679924173"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.   , 0.567, 0.289, 0.354, 0.   , 0.   ],\n",
              "       [0.567, 1.   , 0.873, 0.   , 0.   , 0.   ],\n",
              "       [0.289, 0.873, 1.   , 0.   , 0.   , 0.   ],\n",
              "       [0.354, 0.   , 0.   , 1.   , 0.707, 0.612],\n",
              "       [0.   , 0.   , 0.   , 0.707, 1.   , 0.289],\n",
              "       [0.   , 0.   , 0.   , 0.612, 0.289, 1.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similar(id_doc, matrix):\n",
        "  matrix_sim = cosine_similarity(matrix)\n",
        "  best_sim = -1\n",
        "  id_best_sim = -1;\n",
        "  for id, doc_sim in enumerate(matrix_sim[id_doc]):\n",
        "    if id != id_doc:\n",
        "      if doc_sim > best_sim:\n",
        "        best_sim = doc_sim\n",
        "        id_best_sim = id\n",
        "  return id_best_sim"
      ],
      "metadata": {
        "id": "mziuF_uC7Niq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)\n",
        "print (\"------\")\n",
        "doc_id = 5\n",
        "print(\"Texto: \", df.loc[doc_id]['texts'])\n",
        "print(\"Texto mais parecido: \", df.loc[most_similar(doc_id, rep_array)]['texts'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm2jWoLd7QJY",
        "outputId": "fc2961ca-62a1-475b-933b-5b19cc964817"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts      classes\n",
            "0  Goku is a hero in the Dragon Ball since 1989! ...  Dragon Ball\n",
            "1  The 7 Dragon balls can make wishes come true! ...  Dragon Ball\n",
            "2  If the wishes are superfluous, the dragon ball...  Dragon Ball\n",
            "3  Seiya is a bronze knight and is one of the mai...    Cav. Zod.\n",
            "4  A knight of the zodiac wear a bronze, silver o...    Cav. Zod.\n",
            "5  Saint Seiya: Knights of the Zodiac is a Japane...    Cav. Zod.\n",
            "------\n",
            "Texto:  Saint Seiya: Knights of the Zodiac is a Japanese manga in which mystical warriors called the Saints fight wearing sacred cloths.\n",
            "Texto mais parecido:  Seiya is a bronze knight and is one of the main Knights of the Zodiac. He saved Athena several times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jaccard"
      ],
      "metadata": {
        "id": "Ro-yzMUODUWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Jaccard index is an statistics to compare similarity. Proportion from intersection and union of two set´s.\n",
        "\n",
        "http://bugra.github.io/work/notes/2017-02-07/similarity-via-jaccard-index/"
      ],
      "metadata": {
        "id": "kCDA8pVjT6eR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import pairwise_distances"
      ],
      "metadata": {
        "id": "DnF85_h3Ao3x"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rF93rmYdC-NA"
      },
      "outputs": [],
      "source": [
        "def most_similar(id_doc, matrix):\n",
        "  matrix_sim = 1 - pairwise_distances(matrix, metric='jaccard') # como é medida de distância (valor entre 0 e 1), utilizar o complemento\n",
        "  best_sim = -1\n",
        "  id_best_sim = -1;\n",
        "  for id, doc_sim in enumerate(matrix_sim[id_doc]):\n",
        "    if id != id_doc:\n",
        "      if doc_sim > best_sim:\n",
        "        best_sim = doc_sim\n",
        "        id_best_sim = id\n",
        "  return id_best_sim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_sim = 1 - pairwise_distances(rep_array, metric='jaccard')\n",
        "matrix_sim\n",
        "roundix = np.round(matrix_sim, 3)\n",
        "roundix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNuHX7ncC6Sg",
        "outputId": "006ce8d8-566c-4842-e068-1f8d8894cba0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py:2025: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.   , 0.333, 0.167, 0.2  , 0.   , 0.   ],\n",
              "       [0.333, 1.   , 0.75 , 0.   , 0.   , 0.   ],\n",
              "       [0.167, 0.75 , 1.   , 0.   , 0.   , 0.   ],\n",
              "       [0.2  , 0.   , 0.   , 1.   , 0.5  , 0.375],\n",
              "       [0.   , 0.   , 0.   , 0.5  , 1.   , 0.167],\n",
              "       [0.   , 0.   , 0.   , 0.375, 0.167, 1.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") # don´t print warning due to non binary values\n",
        "\n",
        "print(df)\n",
        "print (\"------\")\n",
        "doc_id = 5\n",
        "print(\"Texto: \", df.loc[doc_id]['texts'])\n",
        "print(\"Texto mais parecido: \", df.loc[most_similar(doc_id, rep_array)]['texts'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TsXbLK8A3si",
        "outputId": "1944e7df-3e74-4a3b-c369-65ad4f000b6f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts      classes\n",
            "0  Goku is a hero in the Dragon Ball since 1989! ...  Dragon Ball\n",
            "1  The 7 Dragon balls can make wishes come true! ...  Dragon Ball\n",
            "2  If the wishes are superfluous, the dragon ball...  Dragon Ball\n",
            "3  Seiya is a bronze knight and is one of the mai...    Cav. Zod.\n",
            "4  A knight of the zodiac wear a bronze, silver o...    Cav. Zod.\n",
            "5  Saint Seiya: Knights of the Zodiac is a Japane...    Cav. Zod.\n",
            "------\n",
            "Texto:  Saint Seiya: Knights of the Zodiac is a Japanese manga in which mystical warriors called the Saints fight wearing sacred cloths.\n",
            "Texto mais parecido:  Seiya is a bronze knight and is one of the main Knights of the Zodiac. He saved Athena several times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jaccard backup (testar depois com os mesmos textos das outras)"
      ],
      "metadata": {
        "id": "Z90YkTuoEV_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(x,y):\n",
        "  \"\"\" retorna a similaridade de jaccard entre duas listas \"\"\"\n",
        "  intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
        "  union_cardinality = len(set.union(*[set(x), set(y)]))\n",
        "  return intersection_cardinality/float(union_cardinality)\n",
        "\n",
        "texto1 = rep_array[5]\n",
        "texto2 = rep_array[3]\n",
        "\n",
        "print(texto1)\n",
        "print(texto2)\n",
        "\n",
        "print(jaccard_similarity(texto1, texto2))\n",
        "\n",
        "print(matrix_sim[5][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNfbXD3EDjtA",
        "outputId": "f4429055-8a6d-4deb-b72f-92414d68a60a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 1 0 1 0 0 1]\n",
            "[1 0 0 1 0 1 1 1 1 1 0 1]\n",
            "1.0\n",
            "0.375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Euclidiana"
      ],
      "metadata": {
        "id": "_gz4irrEDFjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similar(id_doc, matrix):\n",
        "  matrix_sim = pairwise_distances(matrix, metric='euclidean')\n",
        "  best_sim = 99999999\n",
        "  id_best_sim = -1;\n",
        "  for id, doc_sim in enumerate(matrix_sim[id_doc]):\n",
        "    if id != id_doc:\n",
        "      if doc_sim <= best_sim:\n",
        "        best_sim = doc_sim\n",
        "        id_best_sim = id\n",
        "  return id_best_sim"
      ],
      "metadata": {
        "id": "87jEthOnEOGr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_sim = pairwise_distances(rep_array, metric='euclidean')\n",
        "roudex = np.round(matrix_sim,3)\n",
        "roudex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cSeyivLG-iP",
        "outputId": "6080ff3b-7e69-461b-b905-d0f9c35f6405"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.   , 2.236, 2.236, 2.828, 2.828, 2.646],\n",
              "       [2.236, 0.   , 1.414, 3.873, 3.317, 3.162],\n",
              "       [2.236, 1.414, 0.   , 3.317, 2.646, 2.449],\n",
              "       [2.828, 3.873, 3.317, 0.   , 2.   , 2.236],\n",
              "       [2.828, 3.317, 2.646, 2.   , 0.   , 2.236],\n",
              "       [2.646, 3.162, 2.449, 2.236, 2.236, 0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)\n",
        "print (\"------\")\n",
        "doc_id = 5\n",
        "#df.loc[doc_id]['texts']\n",
        "df.loc[most_similar(doc_id, rep_array)]['texts']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Lk-XSJrvETEP",
        "outputId": "1debb534-81d1-47e4-cebd-f1a73941b1c5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts      classes\n",
            "0  Goku is a hero in the Dragon Ball since 1989! ...  Dragon Ball\n",
            "1  The 7 Dragon balls can make wishes come true! ...  Dragon Ball\n",
            "2  If the wishes are superfluous, the dragon ball...  Dragon Ball\n",
            "3  Seiya is a bronze knight and is one of the mai...    Cav. Zod.\n",
            "4  A knight of the zodiac wear a bronze, silver o...    Cav. Zod.\n",
            "5  Saint Seiya: Knights of the Zodiac is a Japane...    Cav. Zod.\n",
            "------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A knight of the zodiac wear a bronze, silver or a gold cloth to protect Athena.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}